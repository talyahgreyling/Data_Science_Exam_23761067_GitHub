---
title: "Data Science Methods for Economics and Finance 871 Exam" 
author: "Talyah Greyling (23761067)"
output:
  md_document:
    variant: markdown_github
---

# PURPOSE: 

This readme is located in my repository for the Data Science Methods for Economics and Finance 871 Exam. 
The repository contains all of my code, figures, tables, and write-ups for the exam. 
There are a total of 5 questions & each question has its own folder with an accompanying Readme, code and data folder.

# SETUP CREATION: 

```{r create folders, eval = FALSE}

#The '23761067' project was created by copying the file path for my repository file (C:/Users/Talyah Greyling/Documents/1) Meesters/1) Data Science 871/Data_Science_Exam_23761067_GitHub) and then using fmxdat::make_project(ProjNam = "23761067"). 

#This code was used to create the question folders: 
location <- "C:/Users/Talyah Greyling/Documents/1) Meesters/1) Data Science 871/Data_Science_Exam_23761067_GitHub"
Texevier::create_template(directory = location, template_name = "Question1")
Texevier::create_template(directory = location, template_name = "Question2")
Texevier::create_template(directory = location, template_name = "Question3")
Texevier::create_template(directory = location, template_name = "Question4")
Texevier::create_template(directory = location, template_name = "Question5")

```

# DATA STORAGE: 

I unzipped the data folder provided (datsci.nfkatzke.com/PracData25.zip) and put each data file in its respective question folder's corresponding data file.
I then added '*data/' to my gitignore to prevent the data folders from committing to GitHub. 

I also stored the 'Practical_25.pdf' in my bin folder. 


# CODE USED FOR FIGURES AND TABLES: 

```{r}

# Basic setup: 
rm(list = ls()) # clean environment
gc() # garbage collection 
library(pacman)
p_load(tidyverse, lubridate)

# Source in all functions: 
list.files('Question1/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question2/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question3/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question4/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question5/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

```




## QUESTION 1: 

### Thought process explained 
* I decided to look at naming trends nationally for the US since this was in line with the clients request to start by showing a time-series representation of the Spearman rank-correlation between each year’s 25 most popular boys’ and girls’ names
and that of the next 3 years and meant that substantial wrangling work was already done in this format. 
* To look at name popularity I decided to look at the top 5 nationally per year for boys and girls respectively, but upon time series visualisation saw that the persistence was too weak over the while time series to generate useful plots. I therefore decided to identify the top 10 names per decade. 

### Loading the data 
```{r}

```

### Time time-series representation of the Spearman rank-correlation
To do this analysis I need to first filter and rank the names by year & gender (boys vs girls), then compare rankings between target and subsequent years and lastly compute the correlations for each year pair. 

### Plot number 1 

### Issues encountered 
* I wrote a function to silently collate the rds files, but upon its creation saw that many of the columns then became unusable by containing an abundance of NAs, I decided to read in each file seperately by adapting the code provided in the assignment. 
