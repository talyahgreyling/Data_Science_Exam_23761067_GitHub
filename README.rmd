---
title: "Data Science Methods for Economics and Finance 871 Exam" 
author: "Talyah Greyling (23761067)"
output:
  md_document:
    variant: markdown_github
---

# PURPOSE: 

This readme is located in my repository for the Data Science Methods for Economics and Finance 871 Exam. 
The repository contains all of my code, figures, tables, and write-ups for the exam. 
There are a total of 5 questions & each question has its own folder with an accompanying Readme, code and data folder.

# SETUP CREATION: 

```{r create folders, eval = FALSE}

#The '23761067' project was created by copying the file path for my repository file (C:/Users/Talyah Greyling/Documents/1) Meesters/1) Data Science 871/Data_Science_Exam_23761067_GitHub) and then using fmxdat::make_project(ProjNam = "23761067"). 

#This code was used to create the question folders: 
location <- "C:/Users/Talyah Greyling/Documents/1) Meesters/1) Data Science 871/Data_Science_Exam_23761067_GitHub"
Texevier::create_template(directory = location, template_name = "Question1")
Texevier::create_template(directory = location, template_name = "Question2")
Texevier::create_template(directory = location, template_name = "Question3")
Texevier::create_template(directory = location, template_name = "Question4")
Texevier::create_template(directory = location, template_name = "Question5")

```

# DATA STORAGE: 

I unzipped the data folder provided (datsci.nfkatzke.com/PracData25.zip) and put each data file in its respective question folder's corresponding data file.
I then added '*data/' to my gitignore to prevent the data folders from committing to GitHub. 

I also stored the 'Practical_25.pdf' in my bin folder. 


# CODE USED FOR FIGURES AND TABLES: 

```{r}

# Basic setup: 
rm(list = ls()) # clean environment
gc() # garbage collection 
library(pacman)
p_load(tidyverse, lubridate)

# Source in all functions: 
list.files('Question1/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question2/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question3/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question4/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question5/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

```

## QUESTION 1: 

### Thought process explained 
* I decided to look at naming trends nationally for the US since this was in line with the clients request to start by showing a time-series representation of the Spearman rank-correlation between each year’s 25 most popular boys’ and girls’ names
and that of the next 3 years and meant that substantial wrangling work was already done in this format. 
* To look at name popularity I decided to look at the top 5 nationally per year for boys and girls respectively, but upon time series visualisation saw that the persistence was too weak over the while time series to generate useful plots. I therefore decided to identify the top 10 names per decade and visualise those in a heatmap. 
* Lastly 

### Loading the data 
```{r}
# Load data
Baby_names <- read_rds("Question1/data/US_Baby_names/Baby_Names_By_US_State.rds")
Top_100_billboard <- read_rds("Question1/data/US_Baby_names/charts.rds")
HBO_titles <- read_rds("Question1/data/US_Baby_names/HBO_titles.rds")
HBO_credits <- read_rds("Question1/data/US_Baby_names/HBO_credits.rds")
```

### Time-series representation of the Spearman rank-correlation
* I created a function 'top_n_names' that filters and ranks the baby names by year & gender (boys vs girls). 
* Thereafter I created a function 'calculate_correlations' that computes the Spearman Rank Correlation for a specific target year
* Then I created a function 'name_persistence' that applies this correlation calculation to all years such that the output can be visually represented. 
* Lastly, the function 'plot_name_persistence' uses geom_smooth to fit a series of lines that represent the rank-correlation over time  

#### Plot number 1 
```{r, warning =  FALSE, fig.align = 'center', fig.cap = "Persistence of National Top 25 Baby Names (1910-2014).\\label{Figure1}", fig.ext = 'png', fig.height = 5, fig.width = 10}
top_names <- Baby_names %>% 
  top_n_names(n = 25)
SpearCorr <- calculate_correlations(top_names, target_year = 2000, future_years = 3)
corr_results <- name_persistence(top_names, future_years = 3)
PersistPlot <- plot_name_persistence(corr_results = corr_results) 
PersistPlot

```

### Popular names 
* After this requested initial rank-correlation analysis it would be useful to see which names were the most popular 
* I created a function 'top_n_names_per_decade' that I use to determine to top 10 boy and girl names respectively per decade
* I then created a function 'popular_names_heatmap' that generates a heatmap to illustrate persistance of the top 10 names in each decade. 

#### Plot number 2
```{r, warning =  FALSE, fig.align = 'center', fig.cap = "Persistence of National Top 10 Baby Names per decade (1910-2014).\\label{Figure2}", fig.ext = 'png', fig.height = 20, fig.width = 10}
pop_names <- Baby_names %>% 
  top_n_names(n = 10)
decade_top_names <- top_n_names_per_decade(pop_names, top_n = 10)
PopNamesMap <- popular_names_heatmap(decade_top_names)
PopNamesMap

```

### Do movies determine popular names 
* TMDB stands for The Movie Database. The percentage is a score given to that movie or TV show by the database users on a 10-star scale. This can give you an idea of how other viewers feel about the show.
* Do people name babies after famous actors/ actresses who play popular movie characters? Define popular as a movie that scores above average on TMDB. 
* To explore this question I created a function 'get_popular_movies' that determines which movies got above average TMDB scores 
*

#### Plot 3 

### Issues encountered 
* I wrote a function to silently collate the rds files, but upon its creation saw that many of the columns then became unusable by containing an abundance of NAs, I decided to read in each file seperately by adapting the code provided in the assignment. 
